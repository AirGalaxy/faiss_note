# Faiss源码阅读
## 1.暴力检索的Index
### 1.1 IndexFlatCodes实现
Index有直接子类IndexFlatCodes，还记的上次我们说的Index类并没有给出具体存储的实现，IndexFlatCodes类就给出了一个简单的实现

### 1.2 IndexFlatCodes的成员变量
```c++
    //每个向量占用code_size个uint8_t
    size_t code_size;

    /// encoded dataset, size ntotal * code_size
    // 以一个vector存储所有的向量
    std::vector<uint8_t> codes;
```

### 1.3 IndexFlatCodes的成员函数
```c++
void IndexFlatCodes::add(idx_t n, const float* x) {
    FAISS_THROW_IF_NOT(is_trained);
    if (n == 0) {
        return;
    }
    codes.resize((ntotal + n) * code_size);
    sa_encode(n, x, codes.data() + (ntotal * code_size));
    ntotal += n;
}
```
先预分配(ntotal + n) * code_size个大小的空间，最后通过sa_encode(n, x, codes.data() + (ntotal * code_size))，直接将(n,x)放到codes.data()的尾部。当然IndexFlatCodes并没有实现sa_encode这个接口，一个朴素的实现可以直接调用``memcpy()``实现

```c++
void IndexFlatCodes::reset() {
    codes.clear();
    ntotal = 0;
}
```
清空所有向量，很简单不解释

```c++
size_t IndexFlatCodes::remove_ids(const IDSelector& sel) {
    idx_t j = 0;
    for (idx_t i = 0; i < ntotal; i++) {
        if (sel.is_member(i)) {
            // should be removed
        } else {
            if (i > j) {
                memmove(&codes[code_size * j],
                        &codes[code_size * i],
                        code_size);
            }
            //j记录了在i的位置前有多少个需要remove的元素
            j++;
        }
    }
    size_t nremove = ntotal - j;
    if (nremove > 0) {
        ntotal = j;
        codes.resize(ntotal * code_size);
    }
    return nremove;
}
```
实现了从codes中移除元素，如果i不需要移除，则i=j，不进行任何操作，若出现一个需要移除的元素，则i = i+1，而j不变，在下一次循环时，将下一个元素向前移动一位，移动到j的位置上，以此类推。最后resize codes这个vector的大小。
由此也可以看出，删除IndexFlatCodes中的元素开销是很大的，或许业务方使用标记删除会更好。

```c++
void IndexFlatCodes::merge_from(Index& otherIndex, idx_t add_id) {
    FAISS_THROW_IF_NOT_MSG(add_id == 0, "cannot set ids in FlatCodes index");
    check_compatible_for_merge(otherIndex);
    IndexFlatCodes* other = static_cast<IndexFlatCodes*>(&otherIndex);
    codes.resize((ntotal + other->ntotal) * code_size);
    memcpy(codes.data() + (ntotal * code_size),
           other->codes.data(),
           other->ntotal * code_size);
    ntotal += other->ntotal;
    other->reset();
}

```
合并两个index也很简单，memcpy直接把other里的数组直接copy过去，之后释放other的数组

## 2.暴力检索-IndexFlat的实现
### 2.1 IndexFlat概述
IndexFlat是IndexFlatCodes的子类，同时支持多种Metric。
### 2.2 IndexFlat的搜索方法
函数定义如下:
```c++
void IndexFlat::search(
        idx_t n,
        const float* x,
        idx_t k,
        float* distances,
        idx_t* labels,
        const SearchParameters* params) const {
    IDSelector* sel = params ? params->sel : nullptr;
    FAISS_THROW_IF_NOT(k > 0);

    // we see the distances and labels as heaps
    if (metric_type == METRIC_INNER_PRODUCT) {
        float_minheap_array_t res = {size_t(n), size_t(k), labels, distances};
        knn_inner_product(x, get_xb(), d, n, ntotal, &res, sel);
    } else if (metric_type == METRIC_L2) {
       ...
    }
}
```
代码结构很清晰，不同的Metric走不同的路线。不同的路线进行搜索的实现的也类似，先建立一个最小堆，然后进行knn的搜索。
```c++
typedef HeapArray<CMin<float, int64_t>> float_minheap_array_t;

template <typename C>
struct HeapArray {
    typedef typename C::TI TI;
    typedef typename C::T T;

    size_t nh; ///< number of heaps
    size_t k;  ///< allocated size per heap
    //向量的id数组
    TI* ids;   ///< identifiers (size nh * k)
    //向量之间的距离
    T* val;    ///< values (distances or similarities), size nh * k
    ...
}
```
float_minheap_array_t是一个模板类的特化，其实现是在HeapArray类中，通过名字我们就可以看出，这是一个通过数组实现的堆。其详细实现后面再看。float_minheap_array_t res构造函数中并没有去建堆，只是拿到了检索向量的个数与每个检索向量需要k个近邻向量。模板参数中的``CMin<float, int64_t>``,float对应query向量与物料向量之间的距离，类型为float，int64_t为物料向量的id的类型
  
接下来以knn_inner_product为例，看下Faiss中暴力检索是怎么做的。  
首先看下knn_inner_product的函数签名
```c++
void knn_inner_product(
        //输入的query向量集合
        const float* x,
        //所有待检索的物料向量
        const float* y,
        //每个向量的维数
        size_t d,
        //query向量有多少个
        size_t nx,
        //物料向量有多少个
        size_t ny,
        //每个query向量要检索k个近邻向量
        size_t k,
        //上文说到的小顶堆&res中的数组，存储的为差值
        float* val,
        //上文说到的小顶堆&res中的数组，存储的为向量的id
        int64_t* ids,
        //SearchParam中的id选择器，检索时只考虑再ID选择器中的向量
        const IDSelector* sel); 
```
接下来看knn_inner_product的实现:
```c++
void knn_inner_product(
        const float* x,
        const float* y,
        size_t d,
        size_t nx,
        size_t ny,
        size_t k,
        float* val,
        int64_t* ids,
        const IDSelector* sel) {
    int64_t imin = 0;
    //如果sel是IDSelectorRange这种范围选择器，直接提取范围就行了
    if (auto selr = dynamic_cast<const IDSelectorRange*>(sel)) {
        imin = std::max(selr->imin, int64_t(0));
        int64_t imax = std::min(selr->imax, int64_t(ny));
        ny = imax - imin;
        y += d * imin;
        sel = nullptr;
    }

    //如果是IDSelectorArray，单独处理，IDSelectorArray提供了is_member接口来判断每个id是不是要检索
    if (auto sela = dynamic_cast<const IDSelectorArray*>(sel)) {
        knn_inner_products_by_idx(
                x, y, sela->ids, d, nx, sela->n, k, val, ids, 0);
        return;
    }

    /** 根据每个query向量要检索的近邻向量的数量k做不同的处理，
    * 大于distance_compute_min_k_reservoir时，走ReservoirResultHandler
    * 否则走HeapResultHandler，distance_compute_min_k_reservoir为全局变量，默认为100
    */
    if (k < distance_compute_min_k_reservoir) {
        using RH = HeapResultHandler<CMin<float, int64_t>>;
        RH res(nx, val, ids, k);
        //根据有没有IDSelector走不同处理
        if (sel) {
            exhaustive_inner_product_seq<RH, true>(x, y, d, nx, ny, res, sel);
        //要检索的query向量太多，就走blas，这个门限为distance_compute_blas_threshold，
        //默认值为20，为全局变量
        } else if (nx < distance_compute_blas_threshold) {
            exhaustive_inner_product_seq(x, y, d, nx, ny, res);
        } else {
            exhaustive_inner_product_blas(x, y, d, nx, ny, res);
        }
    } else {
        //逻辑和上面完全一致
        using RH = ReservoirResultHandler<CMin<float, int64_t>>;
        RH res(nx, val, ids, k);
        if (sel) {
            exhaustive_inner_product_seq<RH, true>(x, y, d, nx, ny, res, sel);
        } else if (nx < distance_compute_blas_threshold) {
            exhaustive_inner_product_seq(x, y, d, nx, ny, res, nullptr);
        } else {
            exhaustive_inner_product_blas(x, y, d, nx, ny, res);
        }
    }
}
```


### 2.2.1 k较小的情况
哎呀，这么多不同的方式，我们先看下看上去最简单的``exhaustive_inner_product_seq(x, y, d, nx, ny, res, sel)``,检索的query向量不多，要检索的相似query的数量也不多


不过在此之前，我们要先看下HeapResultHandler是什么？  
构建一个HeapResultHandler如下:
```c++
RH res(nx, val, ids, k);
```
HeapResultHandler定义如下:
```c++
template <class C>
struct HeapResultHandler {
    //物料向量一共有多少个？
    int nq;
    //物料向量与query之间的距离，来自于上面定义的float_minheap_array_t res
    T* heap_dis_tab;
    //物料向量的id，来自于上面定义的float_minheap_array_t res
    TI* heap_ids_tab;
    //每个query向量要记录k个最近的向量
    int64_t k; // number of results to keep

    HeapResultHandler(size_t nq, T* heap_dis_tab, TI* heap_ids_tab, size_t k)
            : nq(nq),
              heap_dis_tab(heap_dis_tab),
              heap_ids_tab(heap_ids_tab),
              k(k) {}

    /******************************************************
     * API for multiple results (called from 1 thread)
     */

    size_t i0, i1;
    /// begin
    //开始建堆，对id从i0到i1的元素执行heapify的操作
    void begin_multiple(size_t i0, size_t i1) {
        this->i0 = i0;
        this->i1 = i1;
        for (size_t i = i0; i < i1; i++) {
            //注意这里的参数k，代表我们只在以(heap_dis_tab + i * k)为起始地址以长度k的数组上做heapify操作
            //但是根据源码，这里啥也没做，因为我们没传k0
            heap_heapify<C>(k, heap_dis_tab + i * k, heap_ids_tab + i * k);
            
        }
    }
        /// 将id为j0 到 j1对应的distance加入到堆中，这里才开始真正的构建堆
    void add_results(size_t j0, size_t j1, const T* dis_tab) {
        //使用openMP优化
        #pragma omp parallel for
        for (int64_t i = i0; i < i1; i++) {
            //取出当前的id对应的堆数组
            T* heap_dis = heap_dis_tab + i * k;
            TI* heap_ids = heap_ids_tab + i * k;
            //从存放距离的数组中取到当前id=i时对应的距离数组的起始地址
            const T* dis_tab_i = dis_tab + (j1 - j0) * (i - i0) - j0;
            T thresh = heap_dis[0];
            for (size_t j = j0; j < j1; j++) {
                T dis = dis_tab_i[j];
                //如果distance比当前堆顶元素小，就把这个元素插入到堆中
                if (C::cmp(thresh, dis)) {
                    //堆中最多保留k个元素
                    heap_replace_top<C>(k, heap_dis, heap_ids, dis, j);
                    thresh = heap_dis[0];
                }
            }
        }
    }
}

```
如此看来，HeapResultHandler和Lucene中的Collector很类似。使用了OpenMP优化并行执行的速度，所有的结果全部放到一个nx*k的数组里(这样也许是考虑缓存的优化)


接下来来看看exhaustive_inner_product_seq()的实现
```c++
/* Find the nearest neighbors for nx queries in a set of ny vectors */
template <class ResultHandler, bool use_sel = false>
void exhaustive_inner_product_seq(
        const float* x,
        const float* y,
        size_t d,
        size_t nx,
        size_t ny,
        ResultHandler& res,
        const IDSelector* sel = nullptr) {
    using SingleResultHandler = typename ResultHandler::SingleResultHandler;
    #pragma omp parallel num_threads(nt)
    {
        //每个线程添加一个SingleResultHandler
        SingleResultHandler resi(res);
    #pragma omp for
        for (int64_t i = 0; i < nx; i++) {
            const float* x_i = x + i * d;
            const float* y_j = y;

            //初始化
            resi.begin(i);

            for (size_t j = 0; j < ny; j++, y_j += d) {
                //如果使用了IDSelector，在这里判断物料向量是不是需要处理
                if (use_sel && !sel->is_member(j)) {
                    continue;
                }
                float ip = fvec_inner_product(x_i, y_j, d);
                //将距离+物料id添加到数组中
                resi.add_result(ip, j);
            }
            //把元素pop出去，把堆数组原地转换为排序好的数组
            resi.end();
        }
    }
}
```
SingleResultHandler功能与上面提到的HeapResultHandler十分相似，不同的地方在于SingleResultHandler一次只能添加一个(距离，id)到堆中，且没使用OpenMP优化  
可以看到这里的实现是十分朴素的，就是两层循环遍历，然后计算内积。在计算内积时一个需要注意的点是Faiss开启了非精确的浮点数运算以提高速度，代码如下：
```c++
//开启非精确的浮点数运算以提高速度
FAISS_PRAGMA_IMPRECISE_FUNCTION_BEGIN
float fvec_inner_product(const float* x, const float* y, size_t d) {
    float res = 0.F;
    FAISS_PRAGMA_IMPRECISE_LOOP
    for (size_t i = 0; i != d; ++i) {
        res += x[i] * y[i];
    }
    return res;
}
```
OpenBlas优化的exhaustive_inner_product_blas结构也完全类似,只是可以一次计算许多组浮点数
```c++
template <class ResultHandler>
void exhaustive_inner_product_blas(
        const float* x,
        const float* y,
        size_t d,
        size_t nx,
        size_t ny,
        ResultHandler& res) {
            ...
            /* block sizes */
            //一次参与计算的query向量中的浮点数的个数，全局变量，可配置
            const size_t bs_x = distance_compute_blas_query_bs;
            //一次参与计算的物料向量中浮点数的个数，全局变量，可配置
            const size_t bs_y = distance_compute_blas_database_bs;

            for (size_t i0 = 0; i0 < nx; i0 += bs_x) {
            size_t i1 = i0 + bs_x;
            if (i1 > nx)
                i1 = nx;

            res.begin_multiple(i0, i1);

            for (size_t j0 = 0; j0 < ny; j0 += bs_y) {
                size_t j1 = j0 + bs_y;
                if (j1 > ny)
                    j1 = ny;
                /* 调用OpenBlas接口计算内积 */
                {
                    float one = 1, zero = 0;
                    FINTEGER nyi = j1 - j0, nxi = i1 - i0, di = d;
                    sgemm_("Transpose","Not transpose",&nyi,&nxi,&di,&one,y + j0 * d,
                           &di,x + i0 * d,&di,&zero,ip_block.get(),&nyi);
                }

                res.add_results(j0, j1, ip_block.get());
            }
            res.end_multiple();
            InterruptCallback::check();
        }
    }
```
到此为止，在要查找的向量个数k < distance_compute_min_k_reservoir时的情况就分析完了。  


### 2.2.2 k较大的情况
接下来我们分析k >= distance_compute_min_k_reservoir的情况，其实这两种情况并没有特别的不同，只是使用的ResultHandler不同，我们只需要看下ReservoirResultHandler这个类有什么不同之处就行了  
先看看其成员变量
```c++
template <class C>
struct ReservoirResultHandler {
    //query向量与物料向量的距离构成的数组堆
    T* heap_dis_tab;
    //与query向量距离较近的向量的集合，每个query向量对应k个带候选的id
    TI* heap_ids_tab;

    //每个query向量最终保留多少个近邻向量
    int64_t k;       // number of results to keep
    //每个reservoir处理一个query对应的向量，每个reservoir在处理时保留至多capacity个近邻向量
    size_t capacity; // capacity of the reservoirs

    //为reservoirs开辟的vector，添加元素时会添加到这个reservoir_dis、reservoir_ids
    std::vector<T> reservoir_dis;
    std::vector<TI> reservoir_ids;

    //每个query向量的最近邻向量由对应的reservoir处理，一个query向量对应一个reservoir
    std::vector<ReservoirTopN<C>> reservoirs;
}
```
可以看到这里的思路是，对每一个query向量，使用对应reservoir(翻译成存储池?)来处理。当然所有的reservoir都在一个连续的内存上处理，并没有使用类似``std::vector<std::vector<T>>``这样的结构来处理。这里提一点，capacity应该开多大呢?在构造函数中:``capacity = (2 * k + 15) & ~15;``,可以看到是两倍k然后向16取整，向16取整是为了SIMD优化  

接下来看下这里的成员函数
```c++
    // 初始化过程，和HeapResultHandler类似
    void begin_multiple(size_t i0, size_t i1) {
        this->i0 = i0;
        this->i1 = i1;
        //预分配内存
        reservoir_dis.resize((i1 - i0) * capacity);
        reservoir_ids.resize((i1 - i0) * capacity);
        reservoirs.clear();
        for (size_t i = i0; i < i1; i++) {
            //调用reservoir的构造函数
            reservoirs.emplace_back(
                    k,
                    capacity,
                    reservoir_dis.data() + (i - i0) * capacity,
                    reservoir_ids.data() + (i - i0) * capacity);
        }
    }

    // add results for query i0..i1 and j0..j1
    void add_results(size_t j0, size_t j1, const T* dis_tab) {
        // 调用OpenMP并行计算
        #pragma omp parallel for
        for (int64_t i = i0; i < i1; i++) {
            ReservoirTopN<C>& reservoir = reservoirs[i - i0];
            //取得id = i对应的dis_tab数组
            const T* dis_tab_i = dis_tab + (j1 - j0) * (i - i0) - j0;
            for (size_t j = j0; j < j1; j++) {
                T dis = dis_tab_i[j];
                //添加物料向量的id与该物料向量与第i个query向量的距离
                reservoir.add(dis, j);
            }
        }
    }
```
这部分的基本逻辑与HeapResultHandler也基本上是类似的。主要工作由reservoir完成。那我们来看看reservoir到底做了什么呢?
```c++
template <class C>
struct ReservoirTopN {
    size_t i;        // number of stored elements
    size_t n;        // number of requested elements
    size_t capacity; // size of storage

    T threshold; // current threshold
    void add(T val, TI id) {
        if (C::cmp(threshold, val)) {
            if (i == capacity) {
                shrink_fuzzy();
            }
            vals[i] = val;
            ids[i] = id;
            i++;
        }
    }
}
```
这里的做的很明确了，如果当前已存储的id数量不超过capacity，且比当前的阈值要小，就直接添加到vals数组和ids数组中，然后已存储的id的数量加一，这里vals与ids就是reservoir_dis与reservoir_ids对应的段。  
那如果超过了呢，我们就要执行shrink_fuzzy()操作。简单来说就是把已存储的值的数量i限制到[n, (capacity + n) / 2]里，显然我们需要把较大的值淘汰出去，怎么办呢?简单来说就是先用三数中值法先取到一个门限，然后在循环中检查vals数组中满足小于等于该门限的值的数量是否满足在[n, (capacity + n) / 2]中。如果不满足，就在限制了取值的数组中随机3个值进行三数中值法继续找门限。  
这个算法的复杂度是O(n)log(n)
```c++
template <class C>
typename C::T partition_fuzzy_median3(typename C::T* vals,typename C::TI* ids,size_t n,size_t q_min,size_t q_max,size_t* q_out) {
            T thresh_inf = C::Crev::neutral();
            T thresh_sup = C::neutral();
            //第一次三数中值法取到的值
            T thresh = median3(vals[0], vals[n / 2], vals[n - 1]);
            for (int it = 0; it < 200; it++) {
                if (n_lt <= q_min) {
                    if (n_lt + n_eq >= q_min) {
                        q = q_min;
                        break;
                    } else {
                        //不满足条件，将当前找到的门限值作为接下来寻找门限值的条件
                        //thresh_inf变小了
                        thresh_inf = thresh;
                    }
                } else if (n_lt <= q_max) {
                    q = n_lt;
                    break;
                } else {
                    //不满足条件，将当前找到的门限值作为接下来寻找门限值的条件
                    // thresh_sup变大了
                    thresh_sup = thresh;
                }
                //满足条件，break，否则执行下面的代码

                // 三数中值法寻找新门限，只有满足值在[thresh_inf, thresh_sup]中的值才能当作三数中的一个
                // thresh_inf, thresh_sup的值在上面检查是否满足条件的过程中更新，向合适的thresh逼近
                T new_thresh = sample_threshold_median3<C>(vals, n, thresh_inf, thresh_sup);
                if (new_thresh == thresh_inf) {
                    // then there is nothing between thresh_inf and thresh_sup
                    break;
                }
                thresh = new_thresh;
            }
            
        }
```
寻找到合适的门限后，直接在原地对vals、ids数组赋值，并调整有效元素个数i的大小，这样就实现了将较大的元素淘汰。代码如下：
```c++
template <class C>
size_t compress_array(typename C::T* vals,typename C::TI* ids,
        size_t n,typename C::T thresh,size_t n_eq) {
    size_t wp = 0;
    for (size_t i = 0; i < n; i++) {
        if (C::cmp(thresh, vals[i])) {
            vals[wp] = vals[i];
            ids[wp] = ids[i];
            wp++;
        } else if (n_eq > 0 && vals[i] == thresh) {
            vals[wp] = vals[i];
            ids[wp] = ids[i];
            wp++;
            n_eq--;
        }
    }
    assert(n_eq == 0);
    return wp;
}
```

这里只是添加元素，真正的排序在to_result接口中实现：
```c++
    void to_result(T* heap_dis, TI* heap_ids) const {
        for (int j = 0; j < std::min(i, n); j++) {
            //将vals与ids中的元素push到堆中
            heap_push<C>(j + 1, heap_dis, heap_ids, vals[j], ids[j]);
        }

        if (i < n) {
            heap_reorder<C>(i, heap_dis, heap_ids);
            // add empty results
            heap_heapify<C>(n - i, heap_dis + i, heap_ids + i);
        } else {
            // add remaining elements
            heap_addn<C>(n, heap_dis, heap_ids, vals + n, ids + n, i - n);
            heap_reorder<C>(n, heap_dis, heap_ids);
        }
    }
```
to_result()函数在ResultHandler的end()函数中调用，如果你忘了的话可以看下exhaustive_inner_product_seq方法中是不是调用了``resi.end()``，下面给出end()的实现：
```c++
 void end() {
            T* heap_dis = hr.heap_dis_tab + i * hr.k;
            TI* heap_ids = hr.heap_ids_tab + i * hr.k;
            //堆排序，结果放到heap_ids_tab与heap_dis_tab中
            res1.to_result(heap_dis, heap_ids);
        }
```

我们总结下在单个query需要寻找太多个数的近邻向量的情况是怎么处理的  
1. 使用ReservoirResultHandler来收集所有物料id及对应得物料向量到query向量的距离，并提供了批量添加的功能
2. ReservoirResultHandler中会用reservoir来处理一个query的近邻向量，添加物料向量及id的操作实际由reservoir实现，方法就是对数组进行赋值
3. 在添加操作中每个reservoir只会保留capacity个物料向量的信息，当超过capacity时，会对输入的向量进行淘汰，具体做法是通过三数中值法取得门限，然后检查小于门限的值得数量是否满足要求
4. reservoir提供了to_result方法，通过堆排序将reservoir中保存的数组进行排序，得到最终单个query检索的结果

- [ ] <font color=green>能否给出详细的证明在k很大的情况下，使用reservoir更好？</font>

### 2.2.3 为何使用reservoir来处理最近邻的k个物料向量
* 考虑使用容量为k的堆来进行collect，每次调用add_result()时，不论添加的距离大小都需要进行一次插入操作，调整堆的结构，这是使用单纯的堆排序的主要开销。
* 当使用reservoir时，由于我们知道已插入元素中最大元素大小thresh，对于一个新插入元素，直接判断添加元素的大小，若小于等于thresh才执行插入操作，而在达到capacity之前，插入的开销是很小的，只需要一次赋值。真正的开销在于达到capacity之后的寻找新thresh的partition_fuzzy_median3()，这个方法的耗时为O(n)log(n)。在找到新的thresh后还要进行一次数组的压缩(compress_array方法)，耗时为O(n)。  

    考虑k很大的情况下：  
    1. 使用朴素的容量为k的堆排序，每次调整堆的代价是很大的，不论数据的大小每次插入堆中都需要调整堆的接口。而使用reservoir，调整整个reservoir的次数会比k较小的情况下要少。
    2. 在物料向量加入reservoir的过程中，thresh的值会越来越小，越来越接近于真实的最小的第k个值的大小，调整reservoir的频率会越来越低，因为只有比thresh小的值才会添加到reservoir中。

    我相信facebook应该是跑了benchmark找到了这个合适的k值的限制

# 3. IndexFlat总结
我们这里只分析了内积的情况,其实L2的代码可以在Faiss/distance.cpp中找到，extras_metric的情况可以在Faiss/extras_distance.cpp中找到，你会发现，他们和内积的流程没有什么区别，只是在计算距离时的代码不同。不过Faiss会对L1距离做特殊优化，后面会单独分析一下这部分代码  


作为一个暴力检索的Index，也有许多设计上值得挖掘的点，后续我们的搜索引擎也可以考察要采用reservoir来替代目前使用简单的堆实现的collector